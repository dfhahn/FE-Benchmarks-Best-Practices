%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% LIVECOMS ARTICLE TEMPLATE FOR BEST PRACTICES GUIDE
%%% ADAPTED FROM ELIFE ARTICLE TEMPLATE (8/10/2017)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% PREAMBLE
\documentclass[9pt,bestpractices]{livecoms}
% Use the 'onehalfspacing' option for 1.5 line spacing
% Use the 'doublespacing' option for 2.0 line spacing
% Use the 'lineno' option for adding line numbers.
% Use the "ASAPversion' option following article acceptance to add the DOI and relevant dates to the document footer.
% Use the 'pubversion' option for adding the citation and publication information to the document footer, when the LiveCoMS issue is finalized.
% The 'bestpractices' option for indicates that this is a best practices guide.
% Omit the bestpractices option to remove the marking as a LiveCoMS paper.
% Please note that these options may affect formatting.

\usepackage{lipsum} % Required to insert dummy text
\usepackage[version=4]{mhchem}
\usepackage{siunitx}
\DeclareSIUnit\Molar{M}
\usepackage[italic]{mathastext}
\graphicspath{{figures/}}

%% GOOGLE DOCS WHERE ORIGINAL OUTLINE WAS: https://docs.google.com/document/d/1lCGcol6jYLQmcfqrUv9h_FsWygTZzqYxqgjOLCyMoL4/edit

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% IMPORTANT USER CONFIGURATION
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\versionnumber}{0.1}  % you should update the minor version number in preprints and major version number of submissions.
\newcommand{\githubrepository}{\url{https://github.com/openforcefield/FE-Benchmarks-Best-Practices}}  %this should be the main github repository for this article

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% ARTICLE SETUP
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{Best practices for constructing, preparing, and evaluating protein-ligand binding affinity benchmarks [Article v\versionnumber]}
\author[1*]{David F. Hahn}
\author[2]{Hannah E. Bruce Macdonald}
\author[3]{Laura Perez Benito}
\author[2]{John D. Chodera}
\author[4]{Antonia S. J. S. Mey}
\author[5]{David L. Mobley}
\author[6]{Gary Tresadern}
\author[7]{Christopher I. Bayly}
\author[8]{Gregory L. Warren}
\author[2\authfn{1}\authfn{4}]{Firstname Initials Surname}
\affil[1]{Computational Chemistry, Janssen Research \& Development, Turnhoutseweg 30, Beerse B-2340, Belgium}
\affil[2]{Computational and Systems Biology Program, Sloan Kettering Institute, Memorial Sloan Kettering Cancer Center, New York, NY 10065}
\affil[3]{Computational Chemistry, Janssen Research \& Development, Turnhoutseweg 30, Beerse B-2340, Belgium}
\affil[4]{EaStCHEM School of Chemistry, David Brewster Road, Joseph Black Building, The King's Buildings, Edinburgh, EH9 3FJ, UK}
\affil[5]{Departments of Pharmaceutical Sciences and Chemistry, University of California, Irvine, CA USA}
\affil[6]{Computational Chemistry, Janssen Research \& Development, Turnhoutseweg 30, Beerse B-2340, Belgium}
\affil[7]{OpenEye Scientific Software, 9 Bisbee Court, Suite D, Santa Fe, NM 87508 USA}
\affil[8]{DeepCure, 131 Dartmouth St, Boston, MA 02116 USA }
\affil[9]{Institution 9}

\corr{email1@example.com}{FMS}  % Correspondence emails.  FMS and FS are the appropriate authors initials.
\corr{email2@example.com}{FS}

\orcid{David F. Hahn}{0000-0003-2830-6880}
\orcid{Hannah E. Bruce Macdonald}{0000-0002-5562-6866}
\orcid{Antonia S. J. S. Mey}{0000-0001-7512-5252}
\orcid{John D. Chodera}{0000-0003-0542-119X}

\contrib[\authfn{1}]{These authors contributed equally to this work}
\contrib[\authfn{2}]{These authors also contributed equally to this work}

\presentadd[\authfn{3}]{Department, Institute, Country}
\presentadd[\authfn{4}]{Department, Institute, Country}

\blurb{This LiveCoMS document is maintained online on GitHub at \githubrepository; to provide feedback, suggestions, or help improve it, please visit the GitHub repository and participate via the issue tracker.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% PUBLICATION INFORMATION
%%% Fill out these parameters when available
%%% These are used when the "pubversion" option is invoked
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pubDOI{10.XXXX/YYYYYYY}
\pubvolume{<volume>}
\pubissue{<issue>}
\pubyear{<year>}
\articlenum{<number>}
\datereceived{Day Month Year}
\dateaccepted{Day Month Year}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% ARTICLE START
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% GOOGLE DOCS WHERE ORIGINAL OUTLINE WAS: https://docs.google.com/document/d/1lCGcol6jYLQmcfqrUv9h_FsWygTZzqYxqgjOLCyMoL4/edit

\begin{document}

\begin{frontmatter}
\maketitle

\begin{abstract}
Free energy simulations are rapidly becoming a key component to the drug design process and significant efforts have been made to streamline these methods for ease of application. As these tools become more widespread and new innovations in methods and force fields are developed, benchmarking of the performance of free energy calculations on real-world systems becomes critical so that downstream users can have an idea of what level of accuracy is to be expected. Benchmarking also plays a critical role in assessment of progress. Such benchmarking, however, requires construction of well prepared, high quality benchmark sets in order to ensure they provide a realistic assessment of performance. However, the accuracy of results also depends on the set up of the benchmark systems themselves, such as choices made in protein preparation. Diverse choices made in analysis can also impact apparent performance. Here, we address these critical issues by presenting guidelines for selecting good experimental datasets to serve as benchmarks for free energy calculations in order to assess real-world performance as well as possibly identify challenges that remain to be solved. We also give guidelines for preparing systems for binding free energy calculations such as for in benchmarking tests, and make recommendations as to how to analyze the performance of the resulting predictions and draw conclusions about relative performance of different techniques or methods. This work provides a summary of the practices we plan to use in our own benchmarking work on free energy calculations, as well.
\end{abstract}

\end{frontmatter}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The quantitative prediction of protein ligand binding affinity is a key goal of computational assisted drug discovery. The accurate prioritization of ligands for synthesis could deliver substantial efficiency and quality improvements in early drug discovery\cite{abelCriticalReviewValidation2017,abelModelingValuePredictive2018}. Binding free energy (FE) calculations, particularly alchemical binding energy calculations, have emerged as arguably the most promising tool\cite{courniaRelativeBindingFree2017}. Alchemical binding FE methods such as free energy perturbation (FEP)\cite{zwanzigHighTemperatureEquation1954,bennettEfficientEstimationFree1976}, or thermodynamic integration (TI)\cite{kirkwoodQuantumStatisticsAlmost1933,kirkwoodQuantumStatisticsAlmost1934,kirkwoodStatisticalMechanicsFluid1935} have a substantial legacy with the original theory dating back many decades. Seminal work in the 1980’s and 90’s demonstrated applications with organic and biological systems and linked the theory to molecular dynamics (MD) or Monte Carlo (MC) simulation packages.\cite{jorgensenMonteCarloSimulation1985,straatsmaFreeEnergyHydrophobic1986,lybrandTheoreticalCalculationRelative1986,merzFreeEnergyPerturbation1989,pearlmanDeterminationDifferentialEffects1995,choderaAlchemicalFreeEnergy2011,mobleyPerspectiveAlchemicalFree2012} 

Alchemical perturbations in binding FE calculations involve the modification of one chemical moiety to another, or its complete removal or addition, via a chemically unrealistic pathway that can only be achieved in silico such as the transformation of one atom-type to another. Alchemical protein ligand binding FE calculations are often classified as either relative (RBFE) or absolute (ABFE). Whilst the underlying theory is similar, the implementation differs due to use of an alternative thermodynamic cycle. For RBFE the affinity of a ligand to a protein is calculated with respect to another, and involves alchemical perturbations of only the substructures that change between the two ligands. On the other hand, ABFE calculations alchemically remove one entire ligand from solvent and protein. The reader is referred to a recent review of alchemical methods and recommendations for their use.\cite{meyBestPracticesAlchemical2020}

Drug discovery lead optimization (LO) typically involves the synthesis of hundreds of close analogues, with just small structural modifications, in order to identify the optimal leads that show a good balance of target potency and other properties. This makes it an ideal scenario for RBFE where small differences in structure are well suited to alchemical perturbation. A number of recent studies have highlighted the good performance of RBFE for LO datasets. One particularly high profile report from Wang et al\cite{wangAccurateReliablePrediction2015} used their commercial implementation of FEP and reported mean unsigned errors of < XXX kcal/mol. As they pointed out at the time, it is challenging to set up and reliably run RBFE calculations, but their results were robust over a relatively large dataset of 8 protein targets, 200 ligands, and 330 perturbations. It is not reported why these protein-ligand sets were chosen, other than they may be typical of current LO drug discovery. The same group has re-used this dataset to test updates to their force field (CITE, OPLS3 and OPLS3e). Today, this has become the de facto dataset for most subsequent large scale RBFE reports. It has been used to compare the performance of Amber/TI calculations\cite{songUsingAMBER18Relative2019}, XXX, Flare’s FEP (Cresset and Michel group)\cite{kuhnAssessmentBindingAffinity2020} and used as a subset with PMX and Gromacs\cite{gapsysLargeScaleRelative2020} . This dataset has also been used in machine learning studies\cite{jimenezDEEPProteinLigand2018,jimenez-lunaDeltaDeltaNeuralNetworks2019}. In contrast, to date ABFE calculations have not been studied with datasets of a similar scale, although individual reports have shown success accurately predicting binding affinities\cite{aldeghiLargescaleAnalysisWater2018,courniaRigorousFreeEnergy2020}.

Despite the success cases, there are many reports that suggest RBFE calculations still unexpectedly struggle in certain scenarios, scaffold modifications\cite{wangAccurateModelingScaffold2017} and ring expansion\cite{liuRingBreakingFeasible2015}, water displacement (CITE, ), protein flexibility (CITE), applications on GPCRs (CITE), etc. This is manifest in a large-scale study of FEP applied to drug discovery projects at Merck KGaA, in which Schindler et al reported several cases of disappointing outcomes.\cite{schindlerLargeScaleAssessmentBinding2020} In addition, new methods and implementation improvements for BFE calculations continue to emerge, for instance the efforts on lambda dynamics\cite{knightMultisiteDynamicsSimulated2011,vilseckPredictingBindingFree2018}, and non-equilibrium RBFE calculations\cite{gapsysLargeScaleRelative2020,rufaChemicalAccuracyAlchemical2020}. Furthermore, there are many other methodologies such as end-point binding FE calculations (for instance MMGBSA, MMPBSA) or pathway based FE calculations that continue to be developed and applied. Therefore, we must balance the increased confidence that simulation-based FE calculations can impact drug discovery, with the need to further understand, test and overcome limitations of the current methods. 

In brief, the three challenges facing all RBFE or ABFE calculations are an accurate representation of the system, an accurate force field, and sufficient sampling. Specific issues such as ‘water displacement’ mentioned above may arise due to the sampling issues associated with kinetically stable water sites, but also due difficulty to model initial water positions in the system setup. Therefore, despite the importance of FE methods to drug discovery and chemical biology it is surprising there are no benchmark sets of standard benchmark methodologies that allow methods to be compared in a manner that will reflect their future performance. The D3R and SAMPL prospective challenges have demonstrated the utility of focusing the community on common benchmark systems and using common methods to analyze performance (CITE). Mobley and Gilson discussed the need for well-chosen benchmark datasets and how this will have multiple benefits to understand and expand the domain of applicability of FE methods\cite{mobleyPredictingBindingFree2017}. They focused on benchmark systems that will confidently converge, and where the underlying issues are well understood, the aim was to describe systems that could be used only to assess method performance in a robust manner. Here we expand the benchmark definition to include accuracy relative to experiment. This has new implications that will be discussed in more detail throughout this article, for instance: reliability of the underlying experimental data (structure and bioactivities), the confidence in the system setup such as protein and ligand preparation, are the alchemical perturbations suitable for RBFE or ABFE, will the dataset be statistically powered, do datasets capture challenging real-world phenomena (are they difficult enough?), and recommendations for analysing results.   

Our approach will augment existing datasets and recommend to clean-up or remove entirely some protein-ligand sets. Inputs will be provided that can be used to reliably launch future applications. Here, we collect the shared learnings regarding considerations in the construction of a useful set of protein-ligand benchmarks, the preparation of these systems for use as a common community-wide benchmark, and the appropriate statistical analyses for assessing the accuracy expected of different methods and how methodologies should be compared to see if they offer statistically distinguishable performance. We also provide a set of open source tools and data repositories that will act as living benchmark sets and statistical analysis tools that mirror the evolving recommendations for how these benchmarks should be conducted, and hope this will become a common standard utilized by the community in publications for assessing performance and comparing methodologies  


\section{Prerequisites}
We assume a basic familiarity with molecular dynamics (MD) simulations, as well as alchemical free energy protocols. If you are unfamiliar with both of these concepts we suggest the best practices guide by Braun et al.~\cite{braunBestPracticesFoundations2019} on molecular simulations and Mey et al.~\cite{meyBestPracticesAlchemical2020} on alchemical free energy calculations as a starting point. 

\section{Checklist}
Here we use a full-page checklist with multiple sections, so it will appear on a separate page of the sample PDF.
Other checklist formats are possible, as shown in the sample \texttt{sample-document.tex} in \url{github.com/livecomsjournal/article_templates/templates}.

Your checklist should include a succinct list of steps that people should follow when carrying out the task in question.
This is provided to ensure certain basic standards are followed and common but critical major errors are avoided.
Note that a checklist is not intended to cover \emph{all} important steps, but rather focus on the most common reasons for failure or incorrect results, or issues which are particularly crucial.


% This provides a checklist which
% - spans a full page
% - consists of multiple sub-checklists
% - exists on a separate page
% This style of checklist will be especially helpful if you want to encourage readers to print and use your checklist in practice, as they
% can easily print it without also printing other material from your manuscript. However, other styles of checklist are also possible (below).

\begin{Checklists*}


\begin{checklist}{Plotting results}
\textbf{Presenting results in an appropriate format: Section~\ref{sec:plotting_results}}
\begin{itemize}
\item Clearly label the data with titles, legends, and captions.
\item Plot results with the dependent variable (calculated) on y-axis, and the independent variable (experimental) on the x-axis. 
\item Ensure that the data are reported in the same units on both axes, and labelled. Where the units are consistent, the scale of the axis in real space should be consistent, such that a 1 cm change on the x-axis corresponds to the same change in affinity to 1 cm on the y-axis.
\item Plot only one target per plot, unless specifically looking at selectivity.
\end{itemize}
\end{checklist}

\begin{checklist}{Statistical analysis}
\textbf{Quantifying the success of a method: Section~\ref{sec:statistical_analysis}}
\begin{itemize}
\item 
\item Identify which metrics are appropriate for your method. Statistics that measure accuracy, such as RMSE and MUE are commonplace, and additionally correlation statistics are appropriate for absolute free energies, but not relative free energies.
\item Bootstrap statistics to provide confidence intervals. 
\end{itemize}
\end{checklist}


\end{Checklists*}






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Dataset Selection}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

if the comments in the introduction make sense, then as a first point here, before discussing dataset quality (structural and bioactivities), we could have a short section to discuss the aims or purpose of datasets, do we propose a core of very robust datasets that perform well, then adding on increasingly difficult concepts? Concepts can include but not limited to:

Drug discovery interest, representative of classical drug discovery targets and chemistry, chemical and target diversity.

Existing SAMPL/D3R datasets - often created for a reason and with previous performance data available.


Addressing challenges or limitations:

extreme ligand sampling (mcx)

protein sampling (from induced fit to large protein movement)

challenging perturbations, ring formation, ring expansion, linker modifications

charge change (ligands)

protonation state change (protein) - binding sites with crucial His, Cys

water displacement - buried water

covalent binding?

Same chemical series with perturbations that get increasingly larger.

Activity cliffs.





% Choosing an appropriate test system is the first step in validating free energy methods. Factors to consider fall into two overarching categories: quality of the structural data, and quality of the affinity data. The perfect experimental data would be such that if any discrepancy between experiment and computational prediction could be blamed on the computational prediction, and therefore could be blamed on any of the flogging posts of computational chemistry: insufficient sampling, buggy algorithms or poor forcefields.
% Common data sources (structural and binding data, prepared for simulations):
% Requirements (https://agilescientific.com/blog/2019/4/3/what-makes-a-good-benchmark-dataset)
% Publicly available
% Sustainable, long-term
% Easy to use/retrieve
% Interesting (‘Approved by the community’)
% Consistent and high quality data
% Clean
% Documented

% List of common data sources (what do they contain, is the information complete?):
% BindingDB
% Drug Design Data (D3R) Challenges: https://drugdesigndata.org/
% Wang et. al, Schrodinger
% Gapsys et al., Large scale relative protein ligand binding affinities using non-equilibrium alchemy
% Schindler et al., Merck KgGA, fep-benchmark, and associated publication
% Perez-Benito et al., Janssen, Prediciting Activity Cliffs with FEP
% SiliconTx Benchmarks

%-----------------------------------------------------------
\subsection{Structural Data}
\label{sec:struct_data}
%-----------------------------------------------------------

% Source of structure (crystallography/CryoEM/NMR).
% Content of the structure: is the small molecule (or a closely related one) bound? Are there cofactors or cobinders?
% Conditions of structure measurement: temperature, ion concentration, other additives?
% Resolution of the structure:
% Global metrics such as R2 can give an indication of the structure
% Are there crystal contacts? Can you assume the structure in the crystalline form is representative of the biologically active conformation
% Are there missing side chains or residues, or multiple configurations present? Are the termini biologically correct?
% Local resolution: is the active site clearly defined? Is the electron density for the ligand (if there is one) clear? Also are crystallographic waters resolved? Local metrics such as EDIA or Zobs or Spruce(?) can indicate if the electron density is sufficient to support the crystallographic placement of a given atom.
% Iridium publication from Greg Warren, source of a checklist of things to care about: https://doi.org/10.1016/j.drudis.2012.06.011
% Zoe Woody Bryce -- Relative paper in JCIM, things to keep in mind when you’re preparing a protein.

A successful free energy calculation requires a well prepared model of the simulation system, with structures close to its energetic minimum. 
%
The basis for the protein structure is an experimental structure, which is most commonly obtained from X-ray crystallography.
Other sources can be structures from cryo EM, NMR or homology models.
%https://doi.org/10.1021/acs.jcim.7b00564, %https://doi.org/10.1021/acs.jcim.0c00116; %https://doi.org/10.26434/chemrxiv.11364884.v2; 
As free energy calculations are usually run at atomic resolution, the input structure needs to provide the coordinates of all atoms. These are ideally determined by the model.
%
For X-ray structures, this requirement is only met by high quality structures.
The evaluation criteria defined by OpenEye Iridium\cite{warrenEssentialConsiderationsUsing2012} can guide the assessment of X-ray structure. 
%
Regarding the assessment overall quality of the structure (global criteria), the X-ray resolution is often used as it is easily accessible.
%
However, this metric only gives a theoretical limit and not the real quality of the model. Therefore it is not a good metric for quality and should only be used alongside other metrics. Iridium requests a threshold of $< 3.5\,\AA$,\cite{warrenEssentialConsiderationsUsing2012} although more strict thresholds have been suggested (i.e. $<2.0\,\AA$ in a recent benchmark\cite{schindlerLargeScaleAssessmentBinding2020}).
%
More meaningful metrics are $R$, $R_{\mathrm{free}}$ and the coordinate error. 
%
The $R$-factor is a measure for the difference between the predicted data (by the model) and the measured data. A smaller $R$-factor indicates a more consistent model. 
%
The $R_{\mathrm{free}}$-factor is calculated the same way, but uses only a random subset of the measured data. Thus, it can be used to identify overfit models which will be apparent in a larger difference between $R$-factor and $R_{\mathrm{free}}$(typically more than 0.05).
Both $R$-factors are easily accessible for reported crystallographic data, e.g. in the protein data bank (PDB).\cite{bermanProteinDataBank2000} 
%
Additionally to the quality of the model, the quality of the crystal is also included in the coordinate error metric,
%
\begin{equation}
    \mathrm{coordinate error} = \frac{2.22 R_{\mathrm{free}}\sqrt{N_i^3}\sqrt{V_a}} {n_{\mathrm{obs}}^{5/6}},
    \label{eq:coordinate_error}
\end{equation}
%
where $N_i$ is the number of heavy atoms with occupancy of 1, $V_a$ is the volume of the asymmetric unit cell and $n_{\mathrm{obs}}$ is the number of non-Rfree reflections used during refinement. A high-quality structure should have a coordinate error $<0.7$.


Next to the above, global metrics, the local resolution of side chains and ligands in the crystal is of importance for a high quality model. Special care should be taken for the ligand and around the active site. 
%
Ligand atoms where there are crystal packing atoms within $6\,\AA$ should be identified. The electron density around the ligand should be at least partial, which can be checked visually or with a RSCC value > 0.80.
%
All ligand and active site atoms with occupancy <1.0 should be identified.
%
If there is only partial density for the ligand and the active site, these partial-density atoms should be identified and possible alternate conformations should be considered. 
%
Covalently bound ligands should be identified and appropriately modelled.
%Local metrics such as EDIA or Zobs or Spruce(?) can indicate if the electron density is sufficient to support the crystallographic placement of a given atom.


Additional aspects should be considered beyond the quality of the structure (see also structure preparation, Sect. \ref{sec:prep}).
%
The structure of a complex could be deformed due to crystal contacts
or by experimental conditions like additives, pressure or temperature. These conditions might not be representative for the biological environment and therefore biologically active conformation of the complex.
% what can we do about it?
%
Important for the active conformations could be crystal waters, co-factors or co-binders which should be included to model the natural environment of the protein.
%
The ligand in the experimental structure should be sufficiently close to the ligand to be simulated to have a model of the correct binding mode. 
%
A choice of the simulation conditions like temperature, ion concentration, other additives like co-factors or membranes require additional considerations. Ideally, these conditions are close to structural experiment, the affinity measurements and the physiological conditions. Most likely, a trade-off between all of these has to be found. 
    
%
If these requirements are not met, it does not necessarily mean that the data is not usable and the results will be bad. A structure not meeting the requirements just needs more manual work by --- ideally an experienced --- user. Unresolved areas can be modelled with nowadays tools and knowledge about atom interactions.
%
Collective intelligence could be a way to mitigate the influence of individuals to the prepared input structures of a benchmark set. On a platform, other scientists could suggest changes to structures and updated versions could be deposited, increasing the quality of the benchmark set. Endorsement and rating of deposited structures could increase the trust into specific structures and the database in general.

\begin{Checklists*}[p!]

\begin{checklist}{Structural Data}
\begin{itemize}
    \begin{itemize}
    \item Global criteria
        \begin{itemize}
        \item Use coordinate error to select the best structure (< 0.7)
        \item Experimental data is available, i.e. electron density
        \item The reported Rfree < 0.45 when resolution $\le 3.5 \AA$
        \item The reported difference between R and Rfree $\le 0.05$
        \end{itemize}
    \item Local criteria
        \begin{itemize}
        \item Identify ligand atoms where there are crystal packing atoms within 6 $\AA$
        \item The ligand must have at least partial density (check visually or RSCC > 0.80)
        \item All ligand and active site atoms with occupancy <1.0 are identified
        \item Active site atoms with partial density are identified
        \item Also are crystallographic waters resolved
        \item Alternate conformations for ligand and active site atoms are identified
        \item Identify covalent ligands
        \item Are there crystal contacts? 
        \end{itemize}
    \end{itemize}
% \item aspects to be considered beyond the quality of the structure (see also structure preparation, Sect. \ref{sec:prep}
%     \begin{itemize}
%     \item Structure (also the binding mode!) could be deformed due to crystal contacts, additives, experimental temperature,... Can you assume the structure in the crystalline form is representative of the biologically active conformation? 
%     \item Content of the structure: is the small molecule (or a closely related one) bound? 
%     \item Are there cofactors or cobinders which should be included to model the natural environment of the protein?
%     \item Can we model the measurement conditions, temperature, ion concentration, other additives?
%     \item Can we model the natural environment (ion concentration, cofactors, membranes, ...)?
%     \end{itemize}
% \item If these requirements are not met, it does not necessarily mean that the data is not usable and  the results will be bad. A structure not meeting the requirements just needs more manual work by --- ideally an experienced --- user. Unresolved areas can be modelled with nowadays tools and knowledge about atom interactions.
% \item Collective intelligence could be a way to mitigate the influence of individuals to the prepared input structures of a benchmark set. On a platform, other scientists could suggest changes to structures and updated versions could be deposited, increasing the quality of the benchmark set. Endorsement and rating of deposited structures could increase the trust into specific structures and the database in general. 
\end{itemize}
\end{checklist}

\end{Checklists*}

%-----------------------------------------------------------
\subsection{Binding Data}
%-----------------------------------------------------------

% To validate the computational prediction of affinity data, reliable experimental data is required.
% (HBM: ITC is good and everything else is less good?)
% Ideal data would be:
% Single source (publication, laboratory) data should be preferred since it minimizes potential for variation in assay conditions or protocol; 
% Reported with well-quantified errors associated with those
% Ideally with a reasonable N in the set, such that justifiable/robust conclusions may be drawn from the results
% Reasonable dynamic range necessary to separate model from null hypothesis of “guess the mean” +/- Mean Abs Deviation of the data, must be larger than the expected accuracy of free energy methods
% Do we need to also separate from the almost-null hypothesis of "correlation with Molecular Weight" or "correlation with Heavy Atom Count"? 
% Can we develop a useful statistical measure to evaluate if a dataset is good or not?
% Meaningful to relate to a binding free energy
% If kinetics is monitored, must it be Michaelis-Menten or Pseudo Michaelis-Menten? 
% No irreversible covalent inhibitors
% No time-dependent inhibition
% IC50 vs Ki,app: [S] and Km needed for absolute: (single source data can allow for cancellation in DDG)
% Affinities measured on same construct structural studies done on
% Depending on the free energy method that will be used, some considerations might be taken into account for the set of ligands used in the benchmark. Single topology methods rely on some commonality between the molecules being compared, and are more appropriate for a congeneric series of ligands. Absolute methods and dual topology methods are more amenable for comparing sets of small molecules where a change has been made to the scaffold. Similarity between ligands compared is also preferable if assumptions are being made about the binding mode of the ligand - which is tied to the quality, and availability of crystal structures of the system. If the data permitted, an ideal benchmark would be suitable to both absolute and relative free energy methods to allow comparisons.
% What’s the guideline with data which differs from the ideal case or if information about the assay etc. is missing?


% Additional (potential) Issues:
% There are edge cases, that while do not rule a system as a ‘poor test case’, may come with additional complications for simulation. Such examples would be membrane proteins, protein-protein interfaces or covalent binders. 
% For the set of ligands considered, while it is possible to perform calculations for ligands that alter the net charge, involve the breaking of a ring or …., these may also introduce complications that may not be supported in all software packages.
% Often ligand sets include ligands which are outside the experimental measurement range (i.e. affinity lower than detection limit). How should these data points be treated?
% Either should be left out
% Or analysis updates need to be made to treat these as a separate category
% Often these show up in exptl. datasets as having a specific numerical value, but typically this is not correct.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%        Simulation setup and running simulations          %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{How to best setup and run benchmark free energy simulations}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%-----------------------------------------------------------
\subsection{setting up simulations}
\label{sec:setup}
%-----------------------------------------------------------


%-----------------------------------------------------------
\subsubsection{Structure preparation}
\label{sec:prep}
%-----------------------------------------------------------

Starting with an x-ray structure for the protein or protein-ligand complex, the most error-prone stage of protein preparation is the translation from an experimental result into a simulation model: inferring missing atoms and making choices about which x-ray components to include. Having chosen the crystal lattice monomer, you wish to work with based on the criteria in the above section, you may wish to remove some domains of the structure if they are large and unlikely to affect the biological activities you are benchmarking. The truncation of the system needs to be assessed carefully as it has been shown in some cases, such as the dimeric form of PDE2 and the presence of cyclin with CDK2, that a more authentic representation of the system was beneficial for stability during simulations and improved free energy calculations. This is a "biology" decision but by dramatically decreasing the size of the overall simulation system large computational efficiencies can be realized with potentially minimal impact on results. Datasets for benchmarking may be run many times so this efficiency will be meaningful. Working with cryo-EM structures can require an extra step. Even though we can find cryo-EM structures with a resolution around 3 Å, many are still commonly produced in the range of 4 to 10 Å, and in maps with these resolutions it can be difficult to predict side chain positions. Such low-resolution structures may not be appropriate for free energy calculations, better quality cryo-EM may be usable but require using classical MD for extra stability checks and system optimization prior to free energy calculations.

In addition to the protein itself, the subsystem you carry forward from the x-ray structure into simulation may have other components: ligand, cofactors, structured waters, other ligands (if you are simulating a multimer), post-translational modifications (PTMs), and excipients. The cofactors should be deliberately included or excluded based on their role in the biological activity being modeled, removing a cofactor from its cavity might could cause unexpected movements or collapse of the cavity during the simulations so a careful equilibration and solvation of that pocket could be needed. All structured waters close to the protein should be included: in principle the MD sampling could allow waters to find their way in, but experimental and theoretical work has shown that the timescales for this can be impractically long. Also, internal structured waters even very distal from the active site are integral to the protein structure, and omitting them can adversely affect the protein dynamics. Generally, we exclude excipients (often specific to the crystallization media and not present in the assay). PTMs require a judgement call: surface-exposed and distal from the active site they can often be safely excluded, for example glycosylations which could otherwise greatly increase the size of the calculation. This again can save on the overall system size and complexities of parameterization. PTMs proximal to the active site or known to be directly implicated in activity should be retained. Ligands other than that in the active site are again a judgement call: in principal retaining them is only necessary if there is biological cooperativity in the biological assay; in practice this is often not known so in general they should be kept if possible. 

We will consider protein and ligand preparation separately, so if you are beginning with a protein-ligand x-ray for which you want to use the cognate ligand you will want to separate them at this stage; we will consider protein preparation first. The protein itself frequently has missing parts due to the lack of supporting data (electron density) from the x-ray experiment, for example N-terminal and C-terminal protein, mobile loops (e.g. the activation loop in kinases), and residue sidechains. Also, there can be extra parts as "alternate locations" (AltLocs): residue sidechains, or occasionally entire residues or the ligand, for which the experimental density supports more than one distinct orientation in a single x-ray structure solution. For the simulation, the protein must have all the atoms provided for every residue modeled. Missing residue sidechains should always be modeled in, giving them the most preferred rotamer given the local environment. If N- and C-terminal sequence is missing due to disorder (lack of electron density), this is actually an experimental basis for omitting them from the model, but the truncated N- and C-termini should be "capped" by neutral termini, usually an acetate (ACE) cap on the N-terminus and an N-methyl (NME) cap on the C-terminus to mimic the peptide backbone out to the carbon-alpha. Of course, one must be careful not to cap the charged protein termini which are properly resolved in the x-ray: these can be critical for function and/or structure. This "capping" tactic can also treat the termini of "gaps": regions of missing residues over the span of the peptide chain, usually missing loop regions (again due to lack of experimental density). While capping the ends of a loop instead of modeling the whole loop may be acceptable for MD runs of relatively short duration, over longer simulations there is a risk of having the protein around the capped ends of the missing loop gradually lose its structure. Even if a loop is unstructured (and therefore missing in the x-ray structure), it is still holding the ends together! Strategic use of a distance restraint can mitigate this liability. Another possibility for missing loops is to close the ends with a short modeled loop of glycines of sufficient size to link the termini without introducing strain, but not necessarily of the full length of the missing loop. There are several reasons why this can be desirable. If the missing loop is particularly large (for instance >15 or 20 amino acids) accurately modeling its conformation could be challenging and introduce more uncertainty and instability to MD simulations. Furthermore, if the missing loop is distal from the binding site and not expected to affect protein ligand interactions, the replacement only needs to provide a role to stabilize the termini and with the advantage of avoiding the use of restraints. However, a good quality modeling of the missing loop would be preferable. With AltLocs, we have the opposite problem: the experimental data tells us that the fragment exists in two (or more) mutually exclusive orientations experimentally, but we must choose one for our model. Again, this is a judgement call depending on where the AltLoc occurs relative to the active site: distal from the active site, the choice may be less critical; proximal requires more careful consideration. Higher occupancy for one of the AltLocs would be a reason to choose that one for the model.

Once the above issues have been resolved, there remains one more round of decision-making: sidechain flips for HIS, ASN, and GLN, and finally protonation. Protein x-ray experiments cannot resolve the positions of hydrogens, and as importantly they cannot distinguish between different first-row elements O, N, and C: they all look the same. This means that even with good electron density the sidechain orientations of ASN and GLN can have either orientation, swapping O and N positions, and thus interchanging H-bond donors and acceptors. The two possible orientation of HIS sidechains effectively interchange N and C positions in the ring, though it is actually a ring flip. Surface exposed, these different orientations may be of little consequence, but in the interior of the protein, proximal to the active site, or especially interacting with the ligand, this can be very important. In principle these orientations can be sampled over the course of the MD run but only if the trajectory is long enough for the sampling scheme to allow it. Considering that these orientations are experimentally ambiguous, it is a matter of judgement at setup time of whether these sidechains should be reoriented to make a more chemically reasonable model. Historically, the rather long list of tasks above would be done by hand; these days there are a number of tools available to automate many of them... but caveat emptor!

Protonation of the protein model is generally straightforward with one key exception: the ionization state of ionizable sidechains, most particularly ASP and GLU. Active site catalytic CYS is another case requiring care, and occasionally LYS can be deprotonated in some circumstances. The two main determining factors are the pH of the biological milieu and the microscopic environment around the ionizable sidechain. In general, the ionization state of each residue is chosen parametrically during the setup of the protein and remains constant over the course of the simulation, even if the microenvironment changes. There are some "constant pH" MD methods available which down the road could offer a more palatable alternative once they have been integrated with free energy methods. A formal charge on the bound ligand can also affect the ionization state of nearby protein residues; this can be particularly problematic when the ligand charge alchemically changes over the course of a free energy calculation.

In the preparation of the ligand for simulation it is important to verify that the chemical structure is correct. While this is less of a problem for structures generated from small-molecule sources, historically it has been a frequent problem for ligands taken from protein-ligand x-ray structures. Once the underlying chemical structure is correct, the key issue is tautomer and ionization state. As with the ionizable protein residue discussed above, the main factors are the macroscopic pKa of the ligand (for ionization states), the intrinsic relative stability of different tautomer states, and the perturbing effects of the active site microenvironment of the bound ligand. Compounding the complexity is if the unbound ligand (used as a reference state) would have a different tautomer/ionization state. These need to be carefully examined at setup to make sure there is complementarity between the protein and ligand independently of the alchemical change between ligands, and then to flag and resolve alchemical conversions between inconsistent states of the protein.

Once protein and ligand have been prepared, the complex is assembled and solvated in water, or embedded in membrane if the protein belongs to a membrane protein family. In this last case you should use an appropriate equilibrated membrane that matches experimental criteria of thickness and area per lipid as well as the appropriate counter ions. Once the system box is constructed the step involves neutralizing the net charge on the protein-ligand complex, but beyond this a higher concentration of salt (usually sodium chloride) is often warranted to mimic the biological milieu being modeled; most assays are run in a significant salt concentration (100 to 150 mM) to emulate biological environments. The salt concentration can strongly affect experimental binding affinities, particularly with highly polar active sites.

Once the above decisions have been made and the complete simulation system has been set up, it is important to let it relax and equilibrate at simulation temperature and pressure.
A summary of all the important points:
-Choose your system and asses the overall size and domains needed, to remove any parts that will not affect your simulation.

-Check other components of the structure and remove if they do not affect your simulation or system, such as: cofactors, structured waters, other ligands, PTMs.

-Split your protein and ligand to prepare separately.

-For the Protein: 

	Add caps if needed.
    
	If possible, model missing loops, if loops are too long or mobile consider: capping the ends and add a constraint, or model a short GLY loops that links both ends.
    
	Check side chain flips (HIS, ASN, GLN) – particularly that orientations are chosen leading to preferred interactions with the ligand.
    
	Check protonation states – again checking in the context of the interactions that would be formed with the ligand.
    
-For the ligand:

	Check the chemical structure is correct.
  
	Check tautomer and ionizations states.
    
-Assembly the protein and ligand together and solvate or embedded in a membrane. 

-Add ions.

-Equilibrate your system. 


%-----------------------------------------------------------
\subsection{There are specific challenges for alchemical free energy calculation during setup}
\label{sec:alchemical_prep}
%-----------------------------------------------------------

There are an abundance of details that must be considered during the set up of any simulation and in particular for alchemical free energy calculations. The two main differences between an alchemical free energy simulation setup and a conventional MD simulation are: an alchemical perturbation of the small molecules needs to be created, and the assumptions that are made with respect to the environment at the two endstates. In the following we will address all essential choices that need to be made for the setup. For a very detail introduction to best practices for alchemical free energy calculations and a much broader discussion on choices for their setup please refer to the best practices guide~\cite{meyBestPracticesAlchemical2020}. 

\subsubsection{Should I run an absolute or relative free energy calculation?}
There are two possible ways in which to run alchemical free energy calculations, which both provide a free energies of binding, but will require different routes for their setup. \textit{Relative} free energy calculations provide free energies of binding with respect to a reference ligand, meaning that all compounds that are to be assessed for their binding affinity should share a similar scaffold. Whereas \textit{absolute} free energies of binding can be used for a dataset of ligands that do not share any commonalities as the reference state for the free energy of binding is the standard state. This is probably the easiest deciding factor in terms of what kind of calculation to run. If the particular benchmark dataset contains ligands that form a congeneric series then a relative calculation is probably that of choice. Of course congeneric ligand series can be assessed using absolute free energy calculations, or it may be of interest to compare relative to absolute calculations for a given benchmark dataset. 


\subsubsection{Alchemical pathway}

\paragraph{Choices in topology}

\paragraph{Choices around $\lambda$}
In order to connect the initial and final state of the alchemical free energy calculation an alchemical pathway must be chosen. This pathway is regulated by a variable $\vec{\lambda}$, which at $\vec{\lambda}=0$ would mean it represents molecule A and at $\vec{\lambda}=1$ molecule B. As free energy is a statefunction, the computed free energy is in principle independent on the pathway, but different choices in pathway can make the problem computationally more or less tractable. The simplest way to switch between molecule A and B is using a linear switching function for the potential energy of the form:
\begin{equation}
U(\vec{q},\vec{\lambda}) = \vec{\lambda} U_0(\vec{q}) + (1-\vec{\lambda})U_1(\vec{q}),
\end{equation}
where $U$ is the potential energy $\vec{q}$, is the set of positions and $\vec{\lambda}$ the switching parameter. Considerable care needs to be taken in selecting the switching function and spacing of so-called $\lambda$-windows. Common choices are, how many $\lambda$-windows should be used? What functional form should my switching function take? The concept of \textit{difficult} and \textit{easy} transformation is more and more explored, but currently heuristics based on phase space overlap between neighboring $\lambda$-windows is the best way to assess how many windows should be simulated. This can for example be done by looking at the offdiagonals of an overlap matrix~\cite{}. Furthermore, the choice of simulation protocol will influence what switching function and how many $\lambda$-windows should be used. 
%- Alchemical protocol  (Alchemical path, coupling function?), which can be any function, presumably monotonic, that at no stage leaves naked charges.
%- Number of lambda windows - compromise between computational expense and results
%- Spacing of lambda windows - mention trailblaze? But want reasonable exchange (if exchange is happening)



\subsubsection{Choice of Simulation protocol}
There are currently four common types of simulation protocols available, which are summarised in Fig.~\ref{fig:protocols}, these are: Fig.~\ref{fig:protocols} (A) independent replicas, (B) replica exchange, (C) Single replica, self adjusted mixture modelling and (D) non-equilibrium switching. Particularly for (B) and (C) the choice of $\lambda$-spacing will be important, as in (B) it dictates the success of replicas exchanging between $\lambda$s and in (C), often tightly spaced replicas allow for a best exploration. Independent replicas are not necessarily recommended, but are still commonly implemented in software packages. 
\begin{figure}
    \includegraphics[width=0.95\linewidth]{figures/protocol.pdf}
    \caption{\textbf{The four alchemical simulation protocols} (A)xx, (B)xx (C)xx, (D) xx}
    \label{fig:protocols}
\end{figure}

\subsubsection{End-state environments}
- Will the protein be in two distinct conformations when bound to the two ligands, significant active site rearrangement - theoretically fixable with infinite sampling
- Will there be a conformational change in the structure of the ligand scaffold during the alchemical transformation (similar issue as above)  - again infinite sampling would fix this
- Will both endstates have the same active site hydration pattern - again infinite sampling would fix this
- Will a change in the ligand (charge possibly) result in a charge change in the protein - not fixable with infinite sampling (David: Charge change in protein could - theoretically - be also part of the alchemical transformation, no?)

\subsubsection{Perturbation maps for relative calculations}
In relative free energy calculations the choice in which to set up the relative perturbations is very vast and can have a substantial effect on how accurate calculations may turn out to be. The way in which different ligands are connected by relative alchemical calculations is called a perturbation map. In particular for benchmarking it would be vitally important to use the same type of perturbation maps for the same benchmark sets unless new methodologies on how to setup perturbations maps are tested. In this way each edge of the perturbation map will be the same and plots created during the analysis phase later will be comparable. The simplest way of connecting lingands is in a star shaped from to a central crystal structure, with the assumption that all ligands of the congeneric series will bind in the same binding mode as the available crystal -- which may even be confirmed by other crystals, see Fig.~\ref{fig:map} (A), there are different methods available for creating interconnected perturbation maps using LOMAP~\cite{} or Diffnet~\cite{}, as well as some work towards assessing trade off in terms of what network structure will actually provide most reliable estimates with as little computational cost as possible~\cite{}.

\begin{figure}
    \includegraphics[width=0.95\linewidth]{figures/network.pdf}
    \caption{\textbf{Two types of perturbation maps} (A)star map, (B) multi connection map}
    \label{fig:map}
\end{figure}

- inclusion of intermediates
- MCS
- Ring breaking


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                    Simulation analysis                   %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{How to analyse benchmark free energy simulations properly}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%-----------------------------------------------------------
\subsection{Measuring the success of free energy calculations requires careful analysis}
%-----------------------------------------------------------

Reliable reporting and analysis of the success of calculations is vital for the validation and benchmarking of free energy methods as well as the dissemination of published results. This reporting and analysis falls into two major categories -- plotting or visualization of results, and statistical analysis of the results. Here we make recommendations for both categories.

\subsubsection{Plots of free energy results should adhere to certain common standards}
\label{sec:plotting_results}
Figures plotting experimental vs. calculated results are a very useful way to gauge the success of a method or a set of calculations. We recommend several key steps to ensure these plots are valuable, communicate accurate information, and are informative and readable. Experimental values (on the x-axis) should be converted into the same units as the free energy results (on the y-axis), and axes should use the same scale. One common issue with plotting free energy results is that different scales are used on the different axes, which can change the appearance of the results, as illustrated in Figure \ref{fig:plotting-basics}, where changes in the axis and ratios can make the data look more correlated.

\begin{figure}
    \includegraphics[width=0.95\linewidth]{figures/reporting/plotting-basics.pdf}
    \caption{\textbf{Changes to the plotting style can change the appearance of the data.} The above three figures illustrates the same toy data. A) shows the data correctly, with the same units (which are labelled) and scales on both axes. B) shows the same data, however the limits on the y-axis have been changed such that the scales is not consistent. C) is also not consistent, but this is due to the scale of the plot, rather than the limits.}
    \label{fig:plotting-basics}
\end{figure}

Error bars can be very helpful in understanding the uncertainty in the data -- both for calculated values and for experimental values, and thus both experimental and computational error bars should always be included in visualizations of the data. Different sources of error might be used to quantify this, whether an uncertainty directly from a free energy estimator, variance between repeats or a hysteresis-type analysis. How the error bars have been calculated should be reported in the figure caption.\\


Additionally, experimental values which were not actually measured (e.g. values resulting from a measured $K_D$ value which only has experimental bounds, such as $> 5 \mu M$) should not be plotted or should be clearly indicated by different styles and symbols. These data should not be included in the accuracy or correlation statistics discussed in Section \ref{sec:statistical_analysis}, however confusion matrices and reporting sensitivity, specificity and precision can be useful for asserting a models' strength at classifying ligands as binders and non-binders, as demonstrated in \cite{hauserPredictingResistanceClinical2018}.

Finally, plots of results across various targets should typically show one figure per target. Differences in the success of free energy methods can vary widely between targets, and combining the data across targets onto a single plot can obscure actual performance on any given target. Additionally, when considering absolute free energies, the affinity ranges between targets may vary, which may result in analysis picking up the correlation between targets and their affinities, rather than the free energy methods ability to differentiate affinities for a particular target. One exception to this however may be if free energy calculations were being performed for selectivity analysis of similar proteins, whereby the targets are not independent parameters\cite{aldeghiPredictionsLigandSelectivity2017}.

\subsubsection{Consistent reporting of statistics is vital for measuring success}
\label{sec:statistical_analysis}
Free energy calculations fall into two categories: absolute and relative. Depending on which type of result are being analyzed --- absolute or relative --- different statistics will be appropriate. Accuracy statistics, such as root mean squared error (RMSE) and mean unsigned errors (MUE) provide information as to how well the computational method recapitulates the experimental results, and allow for a 'best guess' as to how far the computation prediction of new ligands' affinities may be from experiment. Correlation statistics, such as $R^{2}$, Kendall tau ($\tau$) and Spearman's rank ($\rho$) indicate how well a method does at ordering the results, at identifying the best and worst ligand in a set, which in live drug design projects where these models may be used to make purchasing decisions, may be a more useful metric than accuracy.\\

Additionally, correlation statistics can be sensitive to the number of data points, and the range that they cover. The confidence interval of any metric will be limited by the sample size used to 

This can be exacerbated by experimental uncertainties, which will be covered in Section \ref{section:expt-accuracy}. Some statistical measures are available that attempt to capture the inherent experimental range in the analysis, such as GRAM\cite{} and RRMSE\cite{}.\\

One mistake that is commonly made, is the use of correlation-type statistics for the bench marking of relative free energy calculations. As relative calculations are pairwise comparisons between ligands, the direction, or sign of the calculation is arbitrary. If a ligand $A$ is 2 kcal mol$^{-1}$ higher affinity than ligand $B$, this could equally be plotted and reported as ligand $B$ being -2 kcal mol$^{-1}$ lower affinity than ligand $A$. The consequence of the possible inversion of data points can shift the correlation statistics, despite the underlying data being reliable. The same set of data points can give a range of statistical results depending on arbitrary sign-flips in the data set. While this effect is reduced with increasing data set size, this can still be problematic. If a clear protocol is used, such as mapping all of the results to either be all positive or all negative, or plotting both $A \rightarrow B$ and $B \rightarrow A$ then the statistics quoted will be reproducible, however is possibly best to avoid correlation statistics for relative free energy results.

%-----------------------------------------------------------
\subsubsection{Bootstrapping is a reliable method for determining confidence intervals for statistics}
%-----------------------------------------------------------

While statistics are a useful measure of the performance of a method, it is also important to understand how accurate those measures are themselves. Is a MUE of 1.2 kcal mol$^{-1}$ much better than 1.3 kcal mol$^{-1}$? Would the performance be likely to change on the addition of new ligands in the series? Is the R$^2$ being heavily leveraged by a few outliers? Performing bootstrap analysis allows for confidence intervals to be placed on the statistics, and for these questions to be answered with some confidence. A MUE of 1.2 (0.6) kcal mol$^{-1}$ is not statistically different than a MUE of 1.3 (0.5) kcal mol$^{-1}$. Bootstrap analysis provides a measure of accuracy to the statistics through random sampling with replacement. Bootstrapping should be performed on the data used to compute the statistic reported --- for relative free energies this illustrate how sensitive the statistics are to the edges chosen, and for absolute free energies: the sensitivity to the ligands in the set. If a statistical error is available for each data-point, such as the error afforded from the free energy estimator, then this can be incorporated into the bootstrap estimate, by bootstrapping over a sample taken from each datapoint with it's associated error. It is best practise to report the bootstrapped statistical errors alongside data as 95\% confidence intervals to appropriately evaluate the performance of a particular method, and identify if improvements or changes to a model are statistically significant.

\subsubsection{The maximum achievable computational accuracy is limited by the accuracy of the experimental data}\label{section:expt-accuracy}

Quantifying the experimental uncertainty is necessary for understanding the upper-limit of feasible accuracy for a model.


### how to find/estimate experimental accuracies
If available, the best source of experimental uncertainty is the original source of experimental affinity data, where 
* look for report of experimental uncertainty in literature
* assay reproducibility may be reported, however this on it's own may be an underestimation. 
* different types of assays have different associated errors
* if there is doubt, it is always better to err on the side of larger uncertainty

In addition to reporting experimental uncertainty to track the success of a method, it is useful to understand the upper limit of success a computational method can have for a set of experimental results;

\begin{equation}
    R^2_{max} = 1 - \frac{\sigma(measurement error)}{\sigma(affinity)}
\end{equation}

where $R^2_{max}$ is the highest achievable $R^2$ for a dataset with a standard deviation of affinities ($\sigma(affinity)$) and an experimental uncertainty of  $\sigma(measurement error)$\cite{sheridan2020experimental}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Author Contributions}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% This section mustt describe the actual contributions of
% author. Since this is an electronic-only journal, there is
% no length limit when you describe the authors' contributions,
% so we recommend describing what they actually did rather than
% simply categorizing them in a small number of
% predefined roles as might be done in other journals.
%
% See the policies ``Policies on Authorship'' section of https://livecoms.github.io
% for more information on deciding on authorship and author order.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

(Explain the contributions of the different authors here)
ASJSM: Wrote Sec.~\ref{sec:alchemical_prep} and created Fig.~\ref{fig:map} and Fig.~\ref{fig:protocols}. 


% We suggest you preserve this comment:
For a more detailed description of author contributions,
see the GitHub issue tracking and changelog at \githubrepository.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Other Contributions}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% You should include all people who have filed issues that were
% accepted into the paper, or that upon discussion altered what was in the paper.
% Multiple significant contributions might mean that the contributor
% should be moved to authorship at the discretion of the a
%
% See the policies ``Policies on Authorship'' section of https://livecoms.github.io for
% more information on deciding on authorship and author order.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

(Explain the contributions of any non-author contributors here)
% We suggest you preserve this comment:
For a more detailed description of contributions from the community and others, see the GitHub issue tracking and changelog at \githubrepository.

\section{Potentially Conflicting Interests}
%%%%%%%
%Declare any potentially competing interests, financial or otherwise
%%%%%%%

Declare any potentially conflicting interests here, whether or not they pose an actual conflict in your view.

\section{Funding Information}
%%%%%%%
% Authors should acknowledge funding sources here. Reference specific grants.
%%%%%%%
FMS acknowledges the support of NSF grant CHE-1111111.
JDC acknowledges support from NIH grant P30 CA008748.
We’ll need to acknowledge OpenFF also.

\section*{Author Information}
\makeorcid

\bibliography{livecoms-sample}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% APPENDICES
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\appendix


\end{document}
